{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> Real Time Flight Data Streaming - Spark Structured Streaming Classification </font>\n",
    "**Author:**  Armin Berger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we implemented Spark Structured Streaming to consume the data from task 1 and perform streaming classification. The ML model seeks to determine whether a flight will be delayed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "#### Initialize Spark Session\n",
    "\n",
    "SparkSession is created using a SparkConf object, which would use two local cores\n",
    "with a proper application name, and use UTC as the timezone 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load in all required libraries\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 pyspark-shell'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf \n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "# set up the spark configuartion\n",
    "spark_conf = SparkConf()\\\n",
    ".setMaster('spark://192.168.86.48:7077')\\\n",
    ".set('spark.sql.session.timeZone', 'UTC')\n",
    "\n",
    "# start the spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .appName(\"Flight Data Streaming\") \\\n",
    "    .getOrCreate() \n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed from this project\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark import SparkContext\n",
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, DoubleType, IntegerType, ArrayType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "#from pyspark.ml.classification import NaiveBayes \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "import math \n",
    "import statistics as stat\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "#### Connection to Kafka Producer\n",
    "\n",
    "From the Kafka producers in Task 1, ingest the streaming data into Spark Streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the topic for this session\n",
    "topic = 'flightTopic'\n",
    "\n",
    "# read the stream sent by the producer\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the schema of the data stream\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 \n",
    "\n",
    "#### Setting schema\n",
    "\n",
    "Then the streaming data format should be transformed into the proper formats following the file schema in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the key, value kafka data stream to string format\n",
    "df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a schema in accordance with the original flight data schema\n",
    "flight_schema = ArrayType(StructType([    \n",
    "    StructField('YEAR', StringType(), False),\n",
    "    StructField('MONTH', StringType(), False),\n",
    "    StructField('DAY', StringType(), False),\n",
    "    StructField('DAY_OF_WEEK', StringType(), False),\n",
    "    StructField('AIRLINE', StringType(), False),\n",
    "    StructField('FLIGHT_NUMBER', StringType(), False),\n",
    "    StructField('TAIL_NUMBER', StringType(), False),\n",
    "    StructField('ORIGIN_AIRPORT', StringType(), False),\n",
    "    StructField('DESTINATION_AIRPORT', StringType(), False),\n",
    "    StructField('SCHEDULED_DEPARTURE', StringType(), False),\n",
    "    StructField('DEPARTURE_TIME', StringType(), False),\n",
    "    StructField('DEPARTURE_DELAY', StringType(), False),\n",
    "    StructField('TAXI_OUT', StringType(), False),\n",
    "    StructField('WHEELS_OFF', StringType(), False),\n",
    "    StructField('SCHEDULED_TIME', StringType(), False),\n",
    "    StructField('ELAPSED_TIME', StringType(), False),\n",
    "    StructField('AIR_TIME', StringType(), False),\n",
    "    StructField('DISTANCE', StringType(), False),\n",
    "    StructField('WHEELS_ON', StringType(), False),\n",
    "    StructField('TAXI_IN', StringType(), False),\n",
    "    StructField('SCHEDULED_ARRIVAL', StringType(), False),\n",
    "    StructField('ARRIVAL_TIME', StringType(), False),\n",
    "    StructField('ARRIVAL_DELAY', StringType(), False),\n",
    "    StructField('DIVERTED', StringType(), False),\n",
    "    StructField('CANCELLED', StringType(), False),\n",
    "    StructField('CANCELLATION_REASON', StringType(), False),\n",
    "    StructField('AIR_SYSTEM_DELAY', StringType(), False),\n",
    "    StructField('SECURITY_DELAY', StringType(), False),\n",
    "    StructField('AIRLINE_DELAY', StringType(), False),\n",
    "    StructField('LATE_AIRCRAFT_DELAY', StringType(), False),\n",
    "    StructField('WEATHER_DELAY', StringType(), False),\n",
    "    StructField('ts', StringType(), True) \n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the from_json function to parse the string to the json format based on the defined schema\n",
    "df = df.select(F.from_json(F.col(\"value\").cast(\"string\"), flight_schema).alias('parsed_value'))\n",
    "\n",
    "# we explode the column parsed_value \n",
    "df = df.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))  \n",
    "\n",
    "# after exploding the columns we give them their original titles for easier processing\n",
    "df_formatted = df.select(\n",
    "                    F.col(\"unnested_value.YEAR\").alias(\"YEAR\"),\n",
    "                    F.col(\"unnested_value.MONTH\").alias(\"MONTH\"),\n",
    "                    F.col(\"unnested_value.DAY\").alias(\"DAY\"),\n",
    "                    F.col(\"unnested_value.DAY_OF_WEEK\").alias(\"DAY_OF_WEEK\"),\n",
    "                    F.col(\"unnested_value.AIRLINE\").alias(\"AIRLINE\"),\n",
    "                    F.col(\"unnested_value.FLIGHT_NUMBER\").alias(\"FLIGHT_NUMBER\"),\n",
    "                    F.col(\"unnested_value.TAIL_NUMBER\").alias(\"TAIL_NUMBER\"),\n",
    "                    F.col(\"unnested_value.ORIGIN_AIRPORT\").alias(\"ORIGIN_AIRPORT\"),\n",
    "                    F.col(\"unnested_value.DESTINATION_AIRPORT\").alias(\"DESTINATION_AIRPORT\"),\n",
    "                    F.col(\"unnested_value.SCHEDULED_DEPARTURE\").alias(\"SCHEDULED_DEPARTURE\"),\n",
    "                    F.col(\"unnested_value.DEPARTURE_TIME\").alias(\"DEPARTURE_TIME\"),\n",
    "                    F.col(\"unnested_value.DEPARTURE_DELAY\").alias(\"DEPARTURE_DELAY\"),\n",
    "                    F.col(\"unnested_value.TAXI_OUT\").alias(\"TAXI_OUT\"),\n",
    "                    F.col(\"unnested_value.WHEELS_OFF\").alias(\"WHEELS_OFF\"),\n",
    "                    F.col(\"unnested_value.SCHEDULED_TIME\").alias(\"SCHEDULED_TIME\"),\n",
    "                    F.col(\"unnested_value.ELAPSED_TIME\").alias(\"ELAPSED_TIME\"),\n",
    "                    F.col(\"unnested_value.AIR_TIME\").alias(\"AIR_TIME\"),\n",
    "                    F.col(\"unnested_value.DISTANCE\").alias(\"DISTANCE\"),\n",
    "                    F.col(\"unnested_value.WHEELS_ON\").alias(\"WHEELS_ON\"),\n",
    "                    F.col(\"unnested_value.TAXI_IN\").alias(\"TAXI_IN\"),\n",
    "                    F.col(\"unnested_value.SCHEDULED_ARRIVAL\").alias(\"SCHEDULED_ARRIVAL\"),\n",
    "                    F.col(\"unnested_value.ARRIVAL_TIME\").alias(\"ARRIVAL_TIME\"),\n",
    "                    F.col(\"unnested_value.ARRIVAL_DELAY\").alias(\"ARRIVAL_DELAY\"),\n",
    "                    F.col(\"unnested_value.DIVERTED\").alias(\"DIVERTED\"),\n",
    "                    F.col(\"unnested_value.CANCELLED\").alias(\"CANCELLED\"),\n",
    "                    F.col(\"unnested_value.CANCELLATION_REASON\").alias(\"CANCELLATION_REASON\"),\n",
    "                    F.col(\"unnested_value.AIR_SYSTEM_DELAY\").alias(\"AIR_SYSTEM_DELAY\"),\n",
    "                    F.col(\"unnested_value.SECURITY_DELAY\").alias(\"SECURITY_DELAY\"),\n",
    "                    F.col(\"unnested_value.AIRLINE_DELAY\").alias(\"AIRLINE_DELAY\"),\n",
    "                    F.col(\"unnested_value.LATE_AIRCRAFT_DELAY\").alias(\"LATE_AIRCRAFT_DELAY\"),\n",
    "                    F.col(\"unnested_value.WEATHER_DELAY\").alias(\"WEATHER_DELAY\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"ts\")\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the schema of the new file\n",
    "df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all columns that should be in int format\n",
    "int_cols = ['YEAR',\n",
    " 'MONTH',\n",
    " 'DAY',\n",
    " 'DAY_OF_WEEK',\n",
    " 'FLIGHT_NUMBER',\n",
    " 'SCHEDULED_DEPARTURE',\n",
    " 'DEPARTURE_TIME',\n",
    " 'DEPARTURE_DELAY',\n",
    " 'TAXI_OUT',\n",
    " 'WHEELS_OFF',\n",
    " 'SCHEDULED_TIME',\n",
    " 'ELAPSED_TIME',\n",
    " 'AIR_TIME',\n",
    " 'DISTANCE',\n",
    " 'WHEELS_ON',\n",
    " 'TAXI_IN',\n",
    " 'SCHEDULED_ARRIVAL',\n",
    " 'ARRIVAL_TIME',\n",
    " 'ARRIVAL_DELAY',\n",
    " 'DIVERTED',\n",
    " 'CANCELLED',\n",
    " 'AIR_SYSTEM_DELAY',\n",
    " 'SECURITY_DELAY',\n",
    " 'AIRLINE_DELAY',\n",
    " 'LATE_AIRCRAFT_DELAY',\n",
    " 'WEATHER_DELAY',\n",
    " 'ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all column names in int_cols\n",
    "for col_name in int_cols:\n",
    "    \n",
    "    # cast all required columns to int \n",
    "    df_formatted = df_formatted.withColumn(col_name, col(col_name).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the schema of the new file\n",
    "df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 \n",
    "\n",
    "#### Store data in parquet format\n",
    "\n",
    "Persist the transformed streaming data in parquet format for flight data. Flight data\n",
    "should be stored in “flight.parquet” in the same folder of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into parquet files\n",
    "# write data frame into parquet file format as flight_df and save it in folder flight.parquet\n",
    "query_file_sink = df_formatted.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"flight.parquet/flight_df\")\\\n",
    "        .option(\"checkpointLocation\", \"flight.parquet/flight_df/checkpoint\")\\\n",
    "        .start()\n",
    "\n",
    "\n",
    "# set a timer for 6 min, so that 6 min worth of data are written to the file    \n",
    "t = 360\n",
    "\n",
    "# code for this was taken from geeksforgeeks.org\n",
    "# on the 16/10/2021\n",
    "# link: https://www.geeksforgeeks.org/how-to-create-a-countdown-timer-using-python/\n",
    "\n",
    "# loop through t until it's at\n",
    "while t:\n",
    "    \n",
    "    # save input \n",
    "    mins, secs = divmod(t, 60)\n",
    "    \n",
    "    # create timer\n",
    "    timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "    \n",
    "    # print time left\n",
    "    print(timer, end=\"\\r\")\n",
    "    \n",
    "    # set timer to sleep for 1 sec\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # reduce time counter by one second\n",
    "    t -= 1\n",
    "\n",
    "print('stop writing to file ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the writing of the file into the file sink\n",
    "query_file_sink.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after creating and writing to the parquet file we read the file in again\n",
    "flight_df = spark.read.parquet(\"flight.parquet/flight_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the schema of the read in parquet file\n",
    "flight_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the count\n",
    "flight_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show header of the read in df\n",
    "flight_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "#### Deploy Machine Learning Models \n",
    "\n",
    "Load the machine learning models given, and use the models to classify whether each flight records are delayed. This is based on the assumption that the data has been\n",
    "labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this step I used the models I created previously. We train and test a total of four models. We have two targets, Arrival Delay and Departure Delay, and two types of models, a Decision Tree and a Gradient Boosting tree. \n",
    "\n",
    "### In order to train the models and make predictions a number of data preprocessing steps were required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns deemed to be not useful for our models\n",
    "removed_columns = ['CANCELLATION_REASON','AIR_SYSTEM_DELAY','SECURITY_DELAY',\n",
    "                     'AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that removes unwated columns\n",
    "def eliminate_columns(removed_columns, df):\n",
    "    \n",
    "    # drop the unwated columns\n",
    "    df = df.drop(*removed_columns)\n",
    "    \n",
    "    # return the modified dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function that removes unwated columns\n",
    "flightsRawDf = eliminate_columns(removed_columns, flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with na values\n",
    "flightsDf = flightsRawDf.na.drop(\"any\")\n",
    "\n",
    "# drop rows with null values\n",
    "flightsDf = flightsDf.dropna(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label each flight as either not delayed or delayed\n",
    "def return_label(data):\n",
    "    \n",
    "    val_return = None\n",
    "    \n",
    "    # condition for a flight being late\n",
    "    if data > 5:\n",
    "        \n",
    "        val_return = 1\n",
    "    \n",
    "    # condition for a flight being early\n",
    "    elif data <= 5:\n",
    "        \n",
    "        val_return = 0\n",
    "    \n",
    "    # return binary label \n",
    "    return val_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the function as UDF\n",
    "return_label_udf = udf(return_label,IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the data frame and create two new columns for the binary labels\n",
    "flightsDf = flightsDf\\\n",
    ".withColumn('binaryDeptDelay', return_label_udf('DEPARTURE_DELAY'))\\\n",
    ".withColumn('binaryArrDelay', return_label_udf('ARRIVAL_DELAY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns used for the ML models\n",
    "nums_cols = ['MONTH',\n",
    "            'DAY',\n",
    "            'DAY_OF_WEEK',\n",
    "            'FLIGHT_NUMBER',\n",
    "            'SCHEDULED_DEPARTURE',\n",
    "            'DEPARTURE_TIME',\n",
    "            'DEPARTURE_DELAY',\n",
    "            'TAXI_OUT',\n",
    "            'WHEELS_OFF',\n",
    "            'SCHEDULED_TIME',\n",
    "            'ELAPSED_TIME',\n",
    "            'AIR_TIME',\n",
    "            'DISTANCE',\n",
    "            'WHEELS_ON',\n",
    "            'TAXI_IN',\n",
    "            'SCHEDULED_ARRIVAL',\n",
    "            'ARRIVAL_TIME',\n",
    "            'ARRIVAL_DELAY',\n",
    "            'ts',\n",
    "            'binaryDeptDelay',\n",
    "            'binaryArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselect the required data\n",
    "my_data = flightsDf.select(*nums_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that are in string format and need to be vectorized\n",
    "str_cols = ['AIRLINE', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new column names for the indexing\n",
    "str_cols_names_index = [x + '_index' for x in str_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure index function\n",
    "df_indexer = StringIndexer(inputCols = str_cols, outputCols = str_cols_names_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new column names for the vectors\n",
    "output_cols_ohe = [x + '_vec' for x in str_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set inputs and outputs\n",
    "df_encoder = OneHotEncoder(inputCols = str_cols_names_index, outputCols = output_cols_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector columns\n",
    "vec_cols = ['AIRLINE_vec', 'TAIL_NUMBER_vec', 'ORIGIN_AIRPORT_vec','DESTINATION_AIRPORT_vec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After data preprocessing is done we now train our four models on the above processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a total of four models, 2 for each target and 2 for each type of model\n",
    "\n",
    "# decision tree models\n",
    "dt_bin_dept = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'binaryDeptDelay', maxDepth = 3)\n",
    "dt_bin_arr = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'binaryArrDelay', maxDepth = 3)\n",
    "\n",
    "# gradient boost tree models\n",
    "gbt_bin_dept = GBTClassifier(featuresCol=\"features\", labelCol=\"binaryDeptDelay\", maxIter = 3)\n",
    "gbt_bin_arr = GBTClassifier(featuresCol=\"features\", labelCol=\"binaryArrDelay\", maxIter = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the feature columns used for training and testing the models\n",
    "input_cols = nums_cols + vec_cols\n",
    "\n",
    "# remove the target columns\n",
    "input_cols.remove('binaryDeptDelay')\n",
    "input_cols.remove('binaryArrDelay')\n",
    "input_cols.remove('DEPARTURE_DELAY')\n",
    "input_cols.remove('ARRIVAL_DELAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector assembler, used for training and testing the models \n",
    "assembler = VectorAssembler(inputCols = input_cols, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipline to perform df_indexer, df_encoder,df_encoder_2, assembler all in one go\n",
    "pipeline = Pipeline(stages = [df_indexer, df_encoder, assembler])\n",
    "\n",
    "# fit and transform the bank dataframe\n",
    "engineered = pipeline.fit(flightsDf).transform(flightsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into testing and training\n",
    "# 80 % training and 20 % testing\n",
    "train, test = engineered.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all four models on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# model 1 decision tree and arrival delay\n",
    "dt_bin_arr_model = dt_bin_arr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# model 2 decision tree and departure delay\n",
    "dt_bin_dept_model = dt_bin_dept.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# model 3 gradient boost tree and arrival delay\n",
    "gbt_bin_arr_model = gbt_bin_arr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# model 4 gradient boost tree and departure delay\n",
    "gbt_bin_dept_model = gbt_bin_dept.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for all four models using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with all four models for all four labels \n",
    "dt_arr_pred = dt_bin_arr_model.transform(test)\n",
    "dt_dept_pred = dt_bin_dept_model.transform(test)\n",
    "gbt_arr_pred = gbt_bin_arr_model.transform(test)\n",
    "gbt_dept_pred = gbt_bin_dept_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "\n",
    "#### Model Assessment\n",
    "\n",
    "Using the classification results, monitor the data following the requirements below.\n",
    "For each key in keyFlight = ‘1’, keyFlight = ‘2’, and keyFlight = ‘3’, keep track of the accumulated accuracy for every timestamp in the 2-min window for a total of 6 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Your results should include, number of records flight and for each key, including their accumulated accuracy in each timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates a models accumulated accuracy and flight count for each timestamp\n",
    "def compute_metrics(prediction):\n",
    "    \n",
    "    # select the truth lables\n",
    "    tup_arr = (dt_arr_pred_1, dt_arr_pred_2, dt_arr_pred_3, gbt_arr_pred_1, gbt_arr_pred_2, gbt_arr_pred_3)\n",
    "    \n",
    "    # define lable variable\n",
    "    label = None\n",
    "    \n",
    "    # if truth lable is Arrival Delays\n",
    "    if prediction in tup_arr:\n",
    "\n",
    "        label = 'binaryArrDelay'\n",
    "    \n",
    "    # if truth lable is Departure Delays\n",
    "    else:\n",
    "\n",
    "        label = 'binaryDeptDelay'\n",
    "    \n",
    "    # subselect the required df columns and save them as a pd dataframe\n",
    "    prediction = prediction.select('ts','prediction', label).toPandas()\n",
    "    \n",
    "    # save and sort all unqiue timestamps\n",
    "    ts_unique = sorted(pd.unique(prediction.ts))\n",
    "    \n",
    "    # create a list for the accumulated accuracy of each timestamp\n",
    "    acc_list = []\n",
    "    \n",
    "    # loop through all timestamps\n",
    "    for i in range(1,len(ts_unique)): \n",
    "        \n",
    "        # select all the rows in the df with matching timestamp\n",
    "        row = prediction.loc[prediction.ts.isin(ts_unique[0:i]), [label, 'prediction']]\n",
    "        \n",
    "        # count the number of TN, TP, FN, and FP\n",
    "        TN = row.loc[(row['prediction'] == 0) & (row[label] == 0),:].shape[0]\n",
    "        TP = row.loc[(row['prediction'] == 1) & (row[label] == 1),:].shape[0]\n",
    "        FN = row.loc[(row['prediction'] == 0) & (row[label] == 1),:].shape[0]\n",
    "        FP = row.loc[(row['prediction'] == 1) & (row[label] == 0),:].shape[0]\n",
    "        \n",
    "        # calculate the accuracy\n",
    "        accuracy = round((TN+TP)/(TN+TP+FN+FP),4)\n",
    "        \n",
    "        # append the timestamp, accuracy, and number of flighs\n",
    "        acc_list.append((ts_unique[i-1], accuracy, row.shape[0]))\n",
    "    \n",
    "    # return final list\n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subselect the predictions of the four different models with different keyFlights\n",
    "\n",
    "# Arrival Delay Decision Tree Model\n",
    "dt_arr_pred_1 = dt_arr_pred.filter(dt_arr_pred.DAY_OF_WEEK == '1')\n",
    "dt_arr_pred_2 = dt_arr_pred.filter(dt_arr_pred.DAY_OF_WEEK == '2')\n",
    "dt_arr_pred_3 = dt_arr_pred.filter(dt_arr_pred.DAY_OF_WEEK == '3')\n",
    "\n",
    "# Departure Delay Decision Tree Model\n",
    "dt_dept_pred_1 = dt_dept_pred.filter(dt_dept_pred.DAY_OF_WEEK == '1')\n",
    "dt_dept_pred_2 = dt_dept_pred.filter(dt_dept_pred.DAY_OF_WEEK == '2')\n",
    "dt_dept_pred_3 = dt_dept_pred.filter(dt_dept_pred.DAY_OF_WEEK == '3')\n",
    "\n",
    "# Arrival Delay Gradient Boosting Tree Model\n",
    "gbt_arr_pred_1 = gbt_arr_pred.filter(gbt_arr_pred.DAY_OF_WEEK == '1')\n",
    "gbt_arr_pred_2 = gbt_arr_pred.filter(gbt_arr_pred.DAY_OF_WEEK == '2')\n",
    "gbt_arr_pred_3 = gbt_arr_pred.filter(gbt_arr_pred.DAY_OF_WEEK == '3')\n",
    "\n",
    "# Departure Delay Gradient Boosting Tree Model\n",
    "gbt_dept_pred_1 = gbt_dept_pred.filter(gbt_dept_pred.DAY_OF_WEEK == '1')\n",
    "gbt_dept_pred_2 = gbt_dept_pred.filter(gbt_dept_pred.DAY_OF_WEEK == '2')\n",
    "gbt_dept_pred_3 = gbt_dept_pred.filter(gbt_dept_pred.DAY_OF_WEEK == '3')\n",
    "\n",
    "\n",
    "## calculate the accuracy and flight count for each of the four different models with different keyFlights\n",
    "\n",
    "# Arrival Delay Decision Tree Model\n",
    "dt_arr_pred_1_acc = compute_metrics(dt_arr_pred_1)\n",
    "dt_arr_pred_2_acc = compute_metrics(dt_arr_pred_2)\n",
    "dt_arr_pred_3_acc = compute_metrics(dt_arr_pred_3)\n",
    "\n",
    "# Departure Delay Decision Tree Model\n",
    "dt_dept_pred_1_acc = compute_metrics(dt_dept_pred_1)\n",
    "dt_dept_pred_2_acc = compute_metrics(dt_dept_pred_2)\n",
    "dt_dept_pred_3_acc = compute_metrics(dt_dept_pred_3)\n",
    "\n",
    "# Arrival Delay Gradient Boosting Tree Model\n",
    "gbt_arr_pred_1_acc = compute_metrics(gbt_arr_pred_1)\n",
    "gbt_arr_pred_2_acc = compute_metrics(gbt_arr_pred_2)\n",
    "gbt_arr_pred_3_acc = compute_metrics(gbt_arr_pred_3)\n",
    "\n",
    "# Departure Delay Gradient Boosting Tree Model\n",
    "gbt_dept_pred_1_acc = compute_metrics(gbt_dept_pred_1)\n",
    "gbt_dept_pred_2_acc = compute_metrics(gbt_dept_pred_2)\n",
    "gbt_dept_pred_3_acc = compute_metrics(gbt_dept_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the four models save the accuracy and flight count in a list for later visulisation\n",
    "dt_arr_pred_list = [dt_arr_pred_1_acc, dt_arr_pred_2_acc, dt_arr_pred_3_acc]\n",
    "dt_dept_pred_list = [dt_dept_pred_1_acc, dt_dept_pred_2_acc, dt_dept_pred_3_acc]\n",
    "gbt_arr_pred_list = [gbt_arr_pred_1_acc, gbt_arr_pred_2_acc, gbt_arr_pred_3_acc]\n",
    "gbt_dept_pred_list = [gbt_dept_pred_1_acc, gbt_dept_pred_2_acc, gbt_dept_pred_3_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Visualise the data in line charts. Prepare a line chart plot to show the number of flights from the start to the most recent.\n",
    "For this visualisation, You need two subplots. First subplot, the x-axis can be used to represent the timestamp, while y-axis can be used to represent the number of countFlightRecords. For the second subplot,\n",
    "x-axis can be used to represent the timestamp, whereas y-axis can be used to plot the accumMeanAccuracy. For each subplot, the results from all keyFlights (key = ‘1’, key = ‘2’, and key = ‘3’) should be represented in different color legends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have a total of four models, two targets Arrival Delay and Departure Delay, and two types of models, a Decision Tree and a Gradient Boosting tree. Since we have two plots per model, one for countFlightRecords and one for accumMeanAccuracy we have a total of eight plots for this task. For each of the four model predictions we first retreive the data required and then plot it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulisations for Arrival Delay Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set data for Arrival Delay Decision Tree Model\n",
    "\n",
    "# select data for keyFlight = ‘1’\n",
    "ts_x1 = list(map(lambda x: x[0],dt_arr_pred_list[0]))\n",
    "acc_y1 = list(map(lambda x: x[1],dt_arr_pred_list[0]))\n",
    "count_y1 = list(map(lambda x: x[2],dt_arr_pred_list[0]))\n",
    "\n",
    "# select data for keyFlight = ‘2’\n",
    "ts_x2 = list(map(lambda x: x[0],dt_arr_pred_list[1]))\n",
    "acc_y2 = list(map(lambda x: x[1],dt_arr_pred_list[1]))\n",
    "count_y2 = list(map(lambda x: x[2],dt_arr_pred_list[1]))\n",
    "\n",
    "# select data for keyFlight = ‘3’\n",
    "ts_x3 = list(map(lambda x: x[0],dt_arr_pred_list[2]))\n",
    "acc_y3 = list(map(lambda x: x[1],dt_arr_pred_list[2]))\n",
    "count_y3 = list(map(lambda x: x[2],dt_arr_pred_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of countFlightRecords for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, count_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, count_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, count_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('number of countFlightRecords over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accumMeanAccuracy for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, acc_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, acc_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, acc_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('accumMeanAccuracy over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulisations for Departure Delay Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set data for Departure Delay Decision Tree Model\n",
    "\n",
    "# select data for keyFlight = ‘1’\n",
    "ts_x1 = list(map(lambda x: x[0],dt_dept_pred_list[0]))\n",
    "acc_y1 = list(map(lambda x: x[1],dt_dept_pred_list[0]))\n",
    "count_y1 = list(map(lambda x: x[2],dt_dept_pred_list[0]))\n",
    "\n",
    "# select data for keyFlight = ‘2’\n",
    "ts_x2 = list(map(lambda x: x[0],dt_dept_pred_list[1]))\n",
    "acc_y2 = list(map(lambda x: x[1],dt_dept_pred_list[1]))\n",
    "count_y2 = list(map(lambda x: x[2],dt_dept_pred_list[1]))\n",
    "\n",
    "# select data for keyFlight = ‘3’\n",
    "ts_x3 = list(map(lambda x: x[0],dt_dept_pred_list[2]))\n",
    "acc_y3 = list(map(lambda x: x[1],dt_dept_pred_list[2]))\n",
    "count_y3 = list(map(lambda x: x[2],dt_dept_pred_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of countFlightRecords for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, count_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, count_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, count_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('number of countFlightRecords over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accumMeanAccuracy for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, acc_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, acc_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, acc_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('accumMeanAccuracy over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulisations for Arrival Delay Gradient Boosting Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set data for Arrival Delay Gradient Boosting Tree Model\n",
    "\n",
    "# select data for keyFlight = ‘1’\n",
    "ts_x1 = list(map(lambda x: x[0],gbt_arr_pred_list[0]))\n",
    "acc_y1 = list(map(lambda x: x[1],gbt_arr_pred_list[0]))\n",
    "count_y1 = list(map(lambda x: x[2],gbt_arr_pred_list[0]))\n",
    "\n",
    "# select data for keyFlight = ‘2’\n",
    "ts_x2 = list(map(lambda x: x[0],gbt_arr_pred_list[1]))\n",
    "acc_y2 = list(map(lambda x: x[1],gbt_arr_pred_list[1]))\n",
    "count_y2 = list(map(lambda x: x[2],gbt_arr_pred_list[1]))\n",
    "\n",
    "# select data for keyFlight = ‘3’\n",
    "ts_x3 = list(map(lambda x: x[0],gbt_arr_pred_list[2]))\n",
    "acc_y3 = list(map(lambda x: x[1],gbt_arr_pred_list[2]))\n",
    "count_y3 = list(map(lambda x: x[2],gbt_arr_pred_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of countFlightRecords for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, count_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, count_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, count_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('number of countFlightRecords over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accumMeanAccuracy for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, acc_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, acc_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, acc_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('accumMeanAccuracy over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulisations for Departure Delay Gradient Boosting Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set data for Departure Delay Gradient Boosting Tree Model\n",
    "\n",
    "# select data for keyFlight = ‘1’\n",
    "ts_x1 = list(map(lambda x: x[0],gbt_dept_pred_list[0]))\n",
    "acc_y1 = list(map(lambda x: x[1],gbt_dept_pred_list[0]))\n",
    "count_y1 = list(map(lambda x: x[2],gbt_dept_pred_list[0]))\n",
    "\n",
    "# select data for keyFlight = ‘2’\n",
    "ts_x2 = list(map(lambda x: x[0],gbt_dept_pred_list[1]))\n",
    "acc_y2 = list(map(lambda x: x[1],gbt_dept_pred_list[1]))\n",
    "count_y2 = list(map(lambda x: x[2],gbt_dept_pred_list[1]))\n",
    "\n",
    "# select data for keyFlight = ‘3’\n",
    "ts_x3 = list(map(lambda x: x[0],gbt_dept_pred_list[2]))\n",
    "acc_y3 = list(map(lambda x: x[1],gbt_dept_pred_list[2]))\n",
    "count_y3 = list(map(lambda x: x[2],gbt_dept_pred_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of countFlightRecords for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, count_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, count_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the number of countFlightRecords for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, count_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('number of countFlightRecords over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accumMeanAccuracy for keyFlight = ‘1’\n",
    "plt.plot(ts_x1, acc_y1, label = \"keyFlight = ‘1’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘2’\n",
    "plt.plot(ts_x2, acc_y2, label = \"keyFlight = ‘2’\")\n",
    "\n",
    "# plot the accumMeanAccuracy for keyFlight = ‘3’\n",
    "plt.plot(ts_x3, acc_y3, label = \"keyFlight = ‘3’\")\n",
    "\n",
    "# label the plot\n",
    "plt.ylabel('number of countFlightRecords')\n",
    "plt.xlabel('timestamp')\n",
    "plt.xticks( rotation=25 )\n",
    "plt.title('accumMeanAccuracy over time')\n",
    "\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
